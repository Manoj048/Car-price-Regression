{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manoj048/Car-price-Regression/blob/main/02_WordEmbeddings_Word2Vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "4ityi4aH8Eqw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gensim\n",
        "import nltk\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from gensim.models import Word2Vec\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCSGFO-eQGnq",
        "outputId": "d126da31-f409-4e5f-e467-f54b8e9d544d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading 20 newsgroups dataset for categories:\n",
            "['talk.religion.misc', 'comp.graphics', 'sci.space']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "\n",
        "categories = [\n",
        "    'talk.religion.misc',\n",
        "    'comp.graphics',\n",
        "    'sci.space',\n",
        "]\n",
        "\n",
        "print(\"Loading 20 newsgroups dataset for categories:\")\n",
        "print(categories)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ar0RiWqCQQbP",
        "outputId": "01e0c08a-3037-40ae-9463-537e3f75151a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n"
          ]
        }
      ],
      "source": [
        "df = fetch_20newsgroups(subset='all', categories=categories, \n",
        "                             shuffle=False, remove=('headers', 'footers', 'quotes'))\n",
        "labels = df.target\n",
        "true_k = len(np.unique(labels)) ## This should be 3 in this example\n",
        "print(true_k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "r_RckI7JQg92",
        "outputId": "f6b81201-3182-41a4-e2fb-6b45f5b8c59a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'In regards to fractal commpression, I have seen 2 fractal compressed \"movies\".\\nThey were both fairly impressive.  The first one was a 64 gray scale \"movie\" of\\nCasablanca, it was 1.3MB and had 11 minutes of 13 fps video.  It was a little\\ngrainy but not bad at all.  The second one I saw was only 3 minutes but it\\nhad 8 bit color with 10fps and measured in at 1.2MB.\\n\\nI consider the fractal movies a practical thing to explore.  But unlike many \\nother formats out there, you do end up losing resolution.  I don\\'t know what\\nkind of software/hardware was used for creating the \"movies\" I saw but the guy\\nthat showed them to me said it took 5-15 minutes per frame to generate.  But as\\nI said above playback was 10 or more frames per second.  And how else could you\\nput 11 minutes on one floppy disk?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df.data[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ru603XFQoS4",
        "outputId": "4b65bd52-429a-4868-ec0a-3af11b00bf3f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2588"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "len(df.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "l_UuGCPGQ0Lr"
      },
      "outputs": [],
      "source": [
        "data=[]\n",
        "for text in df.data:\n",
        "  data.append(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        },
        "id": "61SNMVuKQ_hd",
        "outputId": "05636efd-e730-4103-be2b-1724db264a60"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nI think I can. Largely as a result of efforts by people reading this group\\nwriting letters and making phone calls the following has happened:\\n\\n1. NASA reprogrammed funds to keep NASP alive in 1991.\\n2. Efforts to kill DC-X and the SSRT progam where twice twarted\\n   (Feb. and June of last year).\\n3. Gouldin kept his job in spite of heavy lobbying against him.\\n\\nThis may not be what Mark was thinking of but it shows that the\\nreaders of sci.space DO have power and influence.\\n\\n  Allen\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "data[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzv66CZrRCYU",
        "outputId": "839d91d1-ec36-418c-af2e-88d15080c6ae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['  I think I can  Largely as a result of efforts by people reading this group writing letters and making phone calls the following has happened      NASA reprogrammed funds to keep NASP alive in          Efforts to kill DC-X and the SSRT progam where twice twarted     Feb  and June of last year      Gouldin kept his job in spite of heavy lobbying against him   This may not be what Mark was thinking of but it shows that the readers of sci space DO have power and influence     Allen ',\n",
              " 'In regards to fractal commpression, I have seen   fractal compressed \"movies\"  They were both fairly impressive   The first one was a    gray scale \"movie\" of Casablanca, it was    MB and had    minutes of    fps video   It was a little grainy but not bad at all   The second one I saw was only   minutes but it had   bit color with   fps and measured in at    MB   I consider the fractal movies a practical thing to explore   But unlike many  other formats out there, you do end up losing resolution   I don\\'t know what kind of software/hardware was used for creating the \"movies\" I saw but the guy that showed them to me said it took  -   minutes per frame to generate   But as I said above playback was    or more frames per second   And how else could you put    minutes on one floppy disk?',\n",
              " 'Background  The Orion spacedrive was a theoretical concept   It would be a drive using thermonuclear explosions to drive a spacecraft  The idea was that you\\'d detonate devices with somewhere from one to ten megatons yield behind a \"pusher plate\" attached to the main spacecraft   The shock wave from the explosions would transfer momentum to the ship     Now, in an atmosphere I can see this   The energy of the explosion heats the atmosphere, which expands explosively and slams a shock wave into the pusher plate   But in a vacuum, only two things I can see are going to hit the plate  fission/fusion products  barium, krypton, helium, neutrons, evaporated bomb casing  and electromagnetic radiation  gammas mostly, some light/heat from irradiated fission products      Would this work?  I can\\'t see the EM radiation impelling very much momentum  especially given the mass of the pusher plate , and it seems to me you\\'re going to get more momentum transfer throwing the bombs out the back of the ship than you get from detonating them once they\\'re there     I must be missing something   Would someone enlighten me via email?    Thanks   --   --Jim ']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "new=[]\n",
        "# data is a list formed by all entries of df.data\n",
        "for i in data:\n",
        "  i=re.sub('[\\s+\\d+:\\.\\)\\( ]',' ',i) #'\\.' spaces, numbers, colon, paranthesis, full stop rmoval\n",
        "  i=re.sub(r'\\S*@\\S*\\s?','',i)  # Email removal\n",
        "  new.append(i)\n",
        "\n",
        "new[0:3]\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aINrss1idyDD",
        "outputId": "2ccfbe49-00db-4ab9-c633-d8855a4127be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "N0M-TFvNbPB0"
      },
      "outputs": [],
      "source": [
        "# new is a list that contains all the data entries from dataframe after preprocessing\n",
        "tokens=[]\n",
        "for text in new:\n",
        "  text= re.sub(r'\\s+',' ',text.lower())\n",
        "  tokens.append(word_tokenize(text))\n",
        "  \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvkMLi49qTkd",
        "outputId": "464aecb8-fc5b-4853-f80f-c33fe20c53ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2588\n",
            "85\n",
            "154\n"
          ]
        }
      ],
      "source": [
        "tokens[0:2]\n",
        "print(len(tokens))\n",
        "print(len(tokens[0]))\n",
        "print(len(tokens[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For more details on the arguements\n",
        "https://radimrehurek.com/gensim/models/word2vec.html#:~:text=hs%20(%7B0%2C%201%7D,usually%20between%205%2D20)."
      ],
      "metadata": {
        "id": "cLvNiT4dgRDW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "1FFSMBv_qW8m"
      },
      "outputs": [],
      "source": [
        "# corpus, \n",
        "# size = vector dimension of the word representation,\n",
        "#size: The number of dimensions of the embeddings and the default is 100.\n",
        "\n",
        "#window: The maximum distance between a target word and words around the target word. The default window is 5.\n",
        "\n",
        "#min_count: The minimum count of words to consider when training the model; \n",
        "#words with occurrence less than this count will be ignored. The default for min_count is 5.\n",
        "# sg: The training algorithm, either CBOW(0) or skip gram(1). The default training algorithm is CBOW.\n",
        "#  hs ({0, 1}, optional) – If 1, hierarchical softmax will be used for model training. \n",
        "# If 0, and negative is non-zero, negative sampling will be used\n",
        "Gensim_model = Word2Vec(tokens,vector_size=50,window=5,sg=1,hs=0, epochs=10 )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HrNkAG8ytsAX",
        "outputId": "e55a9462-ccb0-4ed3-c486-87f77fcbc625"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('documentation', 0.7871972918510437),\n",
              " ('portable', 0.7226742506027222),\n",
              " ('imdisp', 0.6992469429969788),\n",
              " ('grass', 0.6961449384689331)]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "w1='software'\n",
        "Gensim_model.wv.most_similar(positive=w1,topn=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0aj8Sj5uJpD",
        "outputId": "96d482ea-d3dd-4ff7-b3e7-d46e58289985"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('bachelor', 0.6907857060432434),\n",
              " ('sciences', 0.6907344460487366),\n",
              " ('electro-magnetic', 0.6856871843338013),\n",
              " ('department', 0.6664952039718628)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "w1='science'\n",
        "Gensim_model.wv.most_similar(positive=w1,topn=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0-iSFfwuRpM",
        "outputId": "6bca8e20-65ed-421f-a481-87e6b30426c3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('-q', 0.11141394823789597),\n",
              " ('hand', 0.09498467296361923),\n",
              " ('ps', 0.07368414849042892),\n",
              " ('followed', 0.07055161893367767)]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "w1='technology'\n",
        "Gensim_model.wv.most_similar(negative=w1,topn=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w1='technology'\n",
        "Gensim_model.wv.most_similar(positive=w1,topn=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GUdGJg_fe3d",
        "outputId": "272af4d9-def4-4609-c0a0-b4c808c515b8"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('aerospace', 0.8298055529594421),\n",
              " ('marketing', 0.7677119374275208),\n",
              " ('policy', 0.766974687576294),\n",
              " ('demonstrator', 0.7635629773139954)]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DselQrGTuea1",
        "outputId": "45d20075-2709-4968-c5d3-1051fc959173"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.15884385,  0.11386719,  1.0407876 ,  0.77489406, -0.16279471,\n",
              "        0.5885213 ,  0.642327  , -0.15874533, -0.3307163 , -0.46232626,\n",
              "       -0.6740171 , -0.22653297, -0.2508748 ,  0.44945198, -0.3649284 ,\n",
              "        0.32042414,  1.583339  ,  0.03832008, -0.81387514, -0.2818489 ,\n",
              "       -0.05262995,  0.3514307 ,  0.17602348,  0.24945197,  0.06506569,\n",
              "        0.23610637,  0.40906298, -0.64573395, -0.1414611 ,  0.084113  ,\n",
              "        0.08860959,  0.44852197,  0.17711759,  0.22544359,  0.18289371,\n",
              "        0.18594237, -0.11017715, -0.1875838 , -0.7586856 , -0.47800595,\n",
              "        0.08023006,  0.12059887,  0.23713261,  0.18070649,  0.7567296 ,\n",
              "       -0.11049952, -0.46832424, -0.3864114 ,  0.14369407,  0.1065428 ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "Gensim_model.wv.get_vector('science')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341
        },
        "id": "7dbq1eEIgBWN",
        "outputId": "f7cd6ab7-4502-47f9-95c7-0f091855210b"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-8ef265523844>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mGensim_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_similar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Gastroenteritis'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mmost_similar\u001b[0;34m(self, positive, negative, topn, clip_start, clip_end, restrict_vocab, indexer)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m         \u001b[0;31m# compute the weighted average of all keys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m         \u001b[0mmean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_mean_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpre_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpost_normalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m         all_keys = [\n\u001b[1;32m    843\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_KEY_TYPES\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_index_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mget_mean_vector\u001b[0;34m(self, keys, weights, pre_normalize, post_normalize, ignore_missing)\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mtotal_weight\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mignore_missing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Key '{key}' not present in vocabulary\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtotal_weight\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"Key 'Gastroenteritis' not present in vocabulary\""
          ]
        }
      ],
      "source": [
        "Gensim_model.wv.most_similar('Gastroenteritis')#no similar words"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conceptually Word2Vec and fastText have the same goal: to learn vector representations of words. But unlike Word2Vec, which under the hood uses words to predict words, fastText operates at a more granular level with character n-grams. Where words are represented by the sum of the character n-gram vectors.\n",
        "\n",
        "https://radimrehurek.com/gensim/models/fasttext.html?highlight=fasttext#module-gensim.models.fasttext"
      ],
      "metadata": {
        "id": "viMsRbClpJ1r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "0GayZBYfum3C"
      },
      "outputs": [],
      "source": [
        "from gensim.models import FastText\n",
        "model_fast = FastText(tokens, vector_size=100, window=5, min_count=5, workers=4,sg=1) # religion, space and graphics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wcnQbvTvIgQ",
        "outputId": "2cb6f2fe-1f82-4909-8fb3-161576582e20"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('amateur', 0.9448818564414978),\n",
              " ('industrial', 0.9404093623161316),\n",
              " ('strategic', 0.9354268908500671),\n",
              " ('pacastro', 0.9311636090278625),\n",
              " ('chemistry', 0.9300380945205688),\n",
              " ('auxiliary', 0.9260054230690002),\n",
              " ('astral', 0.9242093563079834),\n",
              " ('assessment', 0.9237842559814453),\n",
              " ('category', 0.9230931401252747),\n",
              " ('extraterrestrial', 0.9212397336959839)]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "model_fast.wv.most_similar(\"Gastroenteritis\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gdYRyQRtlXUK"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}